{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.tokenize import word_tokenize as nltk_tokenize\n",
    "from collections import Counter as collections_counter\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer as sk_feature_extract_text_CV\n",
    "from random import randint as random_randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spam/Ham SMS data was obtained from the Kaggle project <br>\n",
    "https://www.kaggle.com/sid321axn/sms-spam-classifier-naive-bayes-ml-algo.<br>\n",
    "The data was loaded into a dataframe and the messages were extracted for cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "_data = pd.read_csv('./spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show head\n",
    "\n",
    "_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "\n",
    "    \"\"\"\n",
    "        Modifies data dataframe in place.\n",
    "            - to lower\n",
    "            - removes stop words     \n",
    "            - removes punctuation       \n",
    "        Parameters:\n",
    "            df (dataframe): dataframe, column 1 = labels, column 2 = message text\n",
    "        Returns:\n",
    "            (None)\n",
    "    \"\"\"\n",
    "\n",
    "    _stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "    for _m in df.iterrows():\n",
    "        _m[1][1] = _m[1][1].lower()\n",
    "        _m[1][1] = _m[1][1].translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "        _m[1][1] = nltk_tokenize(_m[1][1])\n",
    "        _m[1][1] = [_w for _w in _m[1][1] if not _w in _stopwords]\n",
    "        _m[1][1] = ' '.join(_m[1][1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "\n",
    "preprocess(_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data needs to be separated by spam/ham category for term/document and term frequency analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate based on label\n",
    "\n",
    "_spam = _data[_data['Category'] == 'spam']\n",
    "_ham = _data[_data['Category'] == 'ham']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implemented our bag of words by creating a term/document (sparse) matrix and a term frequency (condensed) matrix in order to conduct Baysian analysis. <br>\n",
    "We used a method to create term/document matrices from the following site: https://www.kaggle.com/sid321axn/sms-spam-classifier-naive-bayes-ml-algo <br>\n",
    "This method invoved using the Count Vectorizer class from sklearn to create a list of counts of words found in the data as well as a list of the words themselves. <br>\n",
    "The rows of the dataframe will represent word counts for a given word. <br>\n",
    "The columns will represent the words found in the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tdm(df):\n",
    "    \n",
    "    \"\"\"\n",
    "        generates a term document matrix from input data\n",
    "        Parameters:\n",
    "            df (DataFrame): dataframe with column 1 = labels, column 2 = messages\n",
    "        Returns:\n",
    "            DataFrame: a term document matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    _count_vectorizer = sk_feature_extract_text_CV()\n",
    "    _count_vectorizer.fit(df.iloc[:,1])\n",
    "    _features = _count_vectorizer.get_feature_names_out()\n",
    "    _counts = _count_vectorizer.transform(df.iloc[:,1]).toarray()\n",
    "    return pd.DataFrame(_counts, columns=_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate tdm for spam and ham\n",
    "\n",
    "_tdm = generate_tdm(_data)\n",
    "_spam_tdm = generate_tdm(_spam)\n",
    "_ham_tdm = generate_tdm(_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequency matrices were dataframes with one row for each word found in the dataset an two columns, <br> \n",
    "one for the number of times the word appeard and the other for the word's frequency among the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tfm(df):\n",
    "    \n",
    "    \"\"\"\n",
    "        generates a term frequency matrix from a term document matrix\n",
    "        Parameters:\n",
    "            df (DataFrame): should be a term document matrix\n",
    "        Returns:\n",
    "            DataFrame: a term frequency matrix\n",
    "    \"\"\"\n",
    "    _counts = []\n",
    "    _probability = []\n",
    "    for _label, _data in df.iteritems():\n",
    "        _sum = _data.sum()\n",
    "        _counts.append(_sum)\n",
    "    _sum_of_all_words = sum(_counts)\n",
    "    for _c in _counts:\n",
    "        _probability.append((_c + 1) / (_sum_of_all_words + df.shape[1] + 1)) # shape[1] is the number of unique words in the class\n",
    "    _out_data = {\n",
    "        'word': df.columns,\n",
    "        'count': _counts,\n",
    "        'probability': _probability\n",
    "    }\n",
    "    return pd.DataFrame().from_dict(_out_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated term frequency matrix\n",
    "\n",
    "_spam_tfm = generate_tfm(_spam_tdm)\n",
    "_ham_tfm = generate_tfm(_ham_tdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>call</td>\n",
       "      <td>344</td>\n",
       "      <td>0.023339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>free</td>\n",
       "      <td>216</td>\n",
       "      <td>0.014680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>txt</td>\n",
       "      <td>150</td>\n",
       "      <td>0.010215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>ur</td>\n",
       "      <td>144</td>\n",
       "      <td>0.009809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>mobile</td>\n",
       "      <td>123</td>\n",
       "      <td>0.008389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>disaster</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>dirty</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>dirtiest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>dining</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>zouk</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2879 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  count  probability\n",
       "972       call    344     0.023339\n",
       "1367      free    216     0.014680\n",
       "2607       txt    150     0.010215\n",
       "2644        ur    144     0.009809\n",
       "1825    mobile    123     0.008389\n",
       "...        ...    ...          ...\n",
       "1205  disaster      1     0.000135\n",
       "1203     dirty      1     0.000135\n",
       "1202  dirtiest      1     0.000135\n",
       "1200    dining      1     0.000135\n",
       "2878      zouk      1     0.000135\n",
       "\n",
       "[2879 rows x 3 columns]"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at spam tfm\n",
    "\n",
    "_spam_tfm.sort_values(by=['probability'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>im</td>\n",
       "      <td>451</td>\n",
       "      <td>0.010015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>get</td>\n",
       "      <td>303</td>\n",
       "      <td>0.006735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3889</th>\n",
       "      <td>ltgt</td>\n",
       "      <td>276</td>\n",
       "      <td>0.006137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4574</th>\n",
       "      <td>ok</td>\n",
       "      <td>273</td>\n",
       "      <td>0.006071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>dont</td>\n",
       "      <td>265</td>\n",
       "      <td>0.005894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>hwkeep</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>hwd</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>hut</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>hustle</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7460</th>\n",
       "      <td>〨ud</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7461 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  count  probability\n",
       "3194      im    451     0.010015\n",
       "2645     get    303     0.006735\n",
       "3889    ltgt    276     0.006137\n",
       "4574      ok    273     0.006071\n",
       "1928    dont    265     0.005894\n",
       "...      ...    ...          ...\n",
       "3149  hwkeep      1     0.000044\n",
       "3148     hwd      1     0.000044\n",
       "3145     hut      1     0.000044\n",
       "3144  hustle      1     0.000044\n",
       "7460     〨ud      1     0.000044\n",
       "\n",
       "[7461 rows x 3 columns]"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at ham tfm\n",
    "\n",
    "_ham_tfm.sort_values(by=['probability'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We needed the probabilty for each class; the probability that a given message was spam or ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_probability(df):\n",
    "\n",
    "    \"\"\"\n",
    "        spam = #_spam/#_messages; ham = #_ham/#_messages\n",
    "        Parameters:\n",
    "            df (DataFrame): the data set; can be pre or post processed\n",
    "        Returns: \n",
    "            (dict): {spam: (float), ham: (float)}\n",
    "    \"\"\"\n",
    "\n",
    "    _count = df.shape[0]\n",
    "    _p = {\n",
    "        'spam': df[df['Category'] == 'spam'].count()[0] / _count,\n",
    "        'ham': df[df['Category'] == 'ham'].count()[0] / _count\n",
    "    }\n",
    "    return _p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spam': 0.13406317300789664, 'ham': 0.8659368269921034}\n"
     ]
    }
   ],
   "source": [
    "# calculate probabilites for each class\n",
    "\n",
    "_p_classes = calculate_class_probability(_data)\n",
    "print(_p_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability(message, p_class, class_tfm):\n",
    "\n",
    "    \"\"\"\n",
    "        calculates the probability that a given message belongs to \n",
    "            the class of the class_tfm\n",
    "        Parameters:\n",
    "            message (string): a single message from the data set\n",
    "            p_class (float): probability of class in data set\n",
    "            class_tfm (DataFrame): message probability calculated\n",
    "                for this class's tfm\n",
    "            data_tfm (DataFrame): data set's term frequency matrix\n",
    "        Returns:\n",
    "            float: the probability that the message belongs to the \n",
    "                label of the supplied class_tfm\n",
    "    \"\"\"\n",
    "\n",
    "    _words = message.split()\n",
    "    _words_in_class = class_tfm['count'].sum()\n",
    "    _p_word_not_in_class = 1 / (1 + _words_in_class + class_tfm.shape[0])  # shape[0] is the number of unique words in the class\n",
    "    _p = 1\n",
    "    \n",
    "    for _w in _words:\n",
    "        \n",
    "        # word not in class_tfm\n",
    "        _row = class_tfm[class_tfm['word'] == _w]\n",
    "        if _row.empty:\n",
    "            _p_word = _p_word_not_in_class\n",
    "\n",
    "        # word in class_tfm\n",
    "        else:\n",
    "            _p_word = _row['probability'].iloc[0]\n",
    "\n",
    "        # product\n",
    "        _p *= _p_word\n",
    "\n",
    "    return _p * p_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "\n",
    "_predictions = []\n",
    "for _row in _data.iterrows():\n",
    "    _p_spam = calculate_probability(_row[1][1], _p_classes['spam'], _spam_tfm)\n",
    "    _p_ham = calculate_probability(_row[1][1], _p_classes['ham'], _ham_tfm)\n",
    "    _prediction = 'spam'\n",
    "    if _p_ham > _p_spam:\n",
    "        _prediction = 'ham'\n",
    "    _predictions.append(_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9761306532663316\n"
     ]
    }
   ],
   "source": [
    "# compare predictions\n",
    "\n",
    "_sum = 0\n",
    "for _i,_row in enumerate(_data.iterrows()):\n",
    "    if _row[1][0] != _predictions[_i]:\n",
    "        continue\n",
    "    _sum += 1\n",
    "_score = _sum / _data.shape[0]\n",
    "print(_score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2dfa35b5617741d51c00d54881377e3538a79c89bccdb8d5394d8412b6257d80"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
